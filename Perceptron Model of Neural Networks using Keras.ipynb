{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Activation Function:\n",
    "\n",
    "** Activation function decides whether the output will be on classification or regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lazy function is slow but it improves the overall system resources performance , because it don't take complete data to be processed in a single go, instead it takes the data step by step to avoid putting the complete load of data on a single resource. In this way the performance of our system increases**\n",
    "\n",
    "Types of Activation Functions most commonly used: Relu,Sigmoid,Threshold,tanh \n",
    "\n",
    "#### Activation Function Used for Regression Model : Linear\n",
    "#### Activation Function used for Classification Model : Relu, Sigmoid, Threshold, tanH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron is the model with single neuron\n",
    "\n",
    "### Forward and Backward Propagation:\n",
    "#### Feed forward(Forward Propagation) : feeding the input to neurons\n",
    "#### Backward Propagation : When the Activation function goes back to the previous neurons for making the changes into the current weight as it is giving high cost\n",
    "\n",
    "## Epoch :\n",
    "**A full round of adjustment from first record to last record where the weight values are adjusted for each and every record and those weights are applid to the next record if cost is high than again weights are adjusted...this forward and backward propagation goes until the last record, this whole one cycle is called as 1 epoch, when next epoch starts it applies the best weights found from the last epoch and so on...**\n",
    "\n",
    "hence,Accuracy is proportional to number of Epochs\n",
    "\n",
    "**If error is positive the weight is decreased and if error is negative than weight is increased**\n",
    "## Optimizers\n",
    "**For making the appropriate adjustments in the weights we use optimizers and one of the concept of optimizers is Gradient descent**\n",
    "**The optimizers that use gradient descent concept are : Batch Gradient Descent, Stochastic Gradient Descent, mini gradient descent\n",
    "\n",
    "### Keras is the Front-end and Tensorflow is the back-end of Keras\n",
    "\n",
    "### Keras has two types of Model Architecture : Sequential and Functional\n",
    "Sequential Model is used when input directly goes to hidden layer and from hidden layer to Output layer\n",
    "\n",
    "To use keras for creating the model , we have to import model architecture like Sequential or Functional,for eg.\n",
    "#### from  keras.models import Sequential\n",
    "Type of optimizer we want to use  like Adam or SGD or mini or BGD ,for eg. \n",
    "#### from keras.optimizers import Adam\n",
    "The Dense function to mention the number of Layers we need to train our model, for eg.\n",
    "#### from keras.layers import Dense\n",
    "When we define Dense function we define it as: model.add(Dense(units=1,input_shape=(1,)))\n",
    "##### Here units=1 is number of outputs we want to get for each record of X,\n",
    "##### input_shape=(1,) is a shape of our input data X here 1 means only one feature\n",
    "##### Also we can  define the activation function in the dense function , by default it uses linear activation function and if we want to use other, than we can define it as \"model.add(Dense(units=1, input_shape=(1,), activation='relu')\"\n",
    "\n",
    "Now after adding the layers to the models , we create the model instance by using the compile function of the model variable, and in it we define the loss function to be used, optimizer to be used and inside optimizer we give the learning rate, for eg: \n",
    "##### model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.8))\n",
    "\n",
    "After this we have to fit the model by our training data, also we will define the number of epochs we want to do, like here while fitting the model,we are giving 50 epochs for eg:\n",
    "##### model.fit(X_train,y_train, epochs=50)\n",
    "\n",
    "After fitting the model, the epochs starts running , and intitially the weights are chosen randomly by the oprimizer b , we can see that how much loss is reducing with each epoch round completion, hence when the last epoch runs , they are the best weights adjusted after the specified number of epochs. And we can see the last \n",
    "\n",
    "##### A,B=model.get_weights()\n",
    "To see the weights values of Coefficient and Bias, and assign those values to A and B respectively, Coefficient values are in 2Dimensional and Bias values are 1Dimensional.\n",
    "\n",
    "##### A[0,0]=0.001 , B[0]=0.001, model.set_weights((A,B)) // this way we can also initialize the weights manually\n",
    "\n",
    "##### model.predict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Optimizer internal algorithm explained by small example using GradientTape() function of tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List Comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=[i*i for i in range(0,10) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward and Forward Propagation basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.constant(3.0)\n",
    "y=tf.constant(6.0)\n",
    "w=tf.Variable(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Weight :  1.0 Loss :  3.0 Descent :  -3.0\n",
      "New weight :  4.0\n"
     ]
    }
   ],
   "source": [
    " with tf.GradientTape() as tape:\n",
    "        #Loss or cost function\n",
    "        #neuron : (w*x-y) is Linear Activation function\n",
    "        loss=tf.math.abs(w*x-y)\n",
    "        dx=tape.gradient(loss,w)\n",
    "        print(\"Old Weight : \",w.numpy(),\"Loss : \",loss.numpy(),\"Descent : \",dx.numpy())\n",
    "        #adjusting the weight with descent value\n",
    "        w.assign(w-dx)\n",
    "        print(\"New weight : \",w.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Neural Network Perceptron Model for Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Keras and tensorflow for Weight-Height Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('weight-height.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data['Height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=1,input_shape=(1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer=Adam(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "313/313 [==============================] - 2s 639us/step - loss: 602.7980\n",
      "Epoch 2/25\n",
      "313/313 [==============================] - 0s 521us/step - loss: 558.2118\n",
      "Epoch 3/25\n",
      "313/313 [==============================] - 0s 500us/step - loss: 543.8894\n",
      "Epoch 4/25\n",
      "313/313 [==============================] - 0s 505us/step - loss: 531.9587\n",
      "Epoch 5/25\n",
      "313/313 [==============================] - 0s 505us/step - loss: 519.3839\n",
      "Epoch 6/25\n",
      "313/313 [==============================] - 0s 495us/step - loss: 502.1693\n",
      "Epoch 7/25\n",
      "313/313 [==============================] - 0s 504us/step - loss: 493.7458\n",
      "Epoch 8/25\n",
      "313/313 [==============================] - 0s 508us/step - loss: 476.2371\n",
      "Epoch 9/25\n",
      "313/313 [==============================] - 0s 474us/step - loss: 473.7556\n",
      "Epoch 10/25\n",
      "313/313 [==============================] - 0s 476us/step - loss: 452.9199\n",
      "Epoch 11/25\n",
      "313/313 [==============================] - 0s 499us/step - loss: 441.5640\n",
      "Epoch 12/25\n",
      "313/313 [==============================] - 0s 491us/step - loss: 428.9847\n",
      "Epoch 13/25\n",
      "313/313 [==============================] - 0s 510us/step - loss: 422.1732\n",
      "Epoch 14/25\n",
      "313/313 [==============================] - 0s 643us/step - loss: 411.1016\n",
      "Epoch 15/25\n",
      "313/313 [==============================] - 0s 498us/step - loss: 400.0342\n",
      "Epoch 16/25\n",
      "313/313 [==============================] - 0s 564us/step - loss: 386.7548\n",
      "Epoch 17/25\n",
      "313/313 [==============================] - 0s 619us/step - loss: 377.0950\n",
      "Epoch 18/25\n",
      "313/313 [==============================] - 0s 599us/step - loss: 366.6386\n",
      "Epoch 19/25\n",
      "313/313 [==============================] - 0s 565us/step - loss: 357.9167\n",
      "Epoch 20/25\n",
      "313/313 [==============================] - 0s 522us/step - loss: 351.3481\n",
      "Epoch 21/25\n",
      "313/313 [==============================] - 0s 476us/step - loss: 339.9275\n",
      "Epoch 22/25\n",
      "313/313 [==============================] - 0s 476us/step - loss: 332.2134\n",
      "Epoch 23/25\n",
      "313/313 [==============================] - 0s 494us/step - loss: 325.3246\n",
      "Epoch 24/25\n",
      "313/313 [==============================] - 0s 490us/step - loss: 315.0912\n",
      "Epoch 25/25\n",
      "313/313 [==============================] - 0s 506us/step - loss: 309.0244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d93cd75d90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[198.90196],\n",
       "       [175.6473 ],\n",
       "       [200.10985],\n",
       "       [189.18694],\n",
       "       [180.69707],\n",
       "       [168.62791],\n",
       "       [175.66185],\n",
       "       [173.65755],\n",
       "       [167.5533 ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[4.591147]], dtype=float32), array([-140.14055], dtype=float32)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "A,B=model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[0,0]=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "B[0]=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights((A,B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.]], dtype=float32), array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Above code written again below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('weight-height.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Gender  10000 non-null  object \n",
      " 1   Height  10000 non-null  float64\n",
      " 2   Weight  10000 non-null  float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data['Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['Height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=1,input_shape=(1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 0s 499us/step - loss: 275.5850\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 0s 486us/step - loss: 72.7988\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 0s 497us/step - loss: 56.8840\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 0s 478us/step - loss: 40.0677\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 0s 534us/step - loss: 26.9484\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 0s 537us/step - loss: 17.2386\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 0s 569us/step - loss: 10.3030\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 0s 535us/step - loss: 6.2247\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 0s 523us/step - loss: 4.0791\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 0s 542us/step - loss: 3.0585\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 0s 481us/step - loss: 2.8169\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 0s 475us/step - loss: 2.6126\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 0s 523us/step - loss: 2.5746\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 0s 539us/step - loss: 2.6848\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 0s 518us/step - loss: 3.1081\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 0s 516us/step - loss: 2.8627\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 0s 508us/step - loss: 2.9723\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 0s 524us/step - loss: 2.8811\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 0s 599us/step - loss: 3.2605\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 0s 574us/step - loss: 3.4541\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 0s 516us/step - loss: 2.9750\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 0s 525us/step - loss: 3.1096\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 0s 544us/step - loss: 2.9479\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 0s 516us/step - loss: 2.8744\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 0s 495us/step - loss: 3.4290\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 0s 507us/step - loss: 3.4661\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 0s 493us/step - loss: 2.9102\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 0s 506us/step - loss: 3.2064\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 0s 496us/step - loss: 3.1669\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 0s 502us/step - loss: 3.4719\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 0s 518us/step - loss: 3.0050\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 0s 501us/step - loss: 2.9713\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 0s 521us/step - loss: 3.3941\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 0s 515us/step - loss: 3.0354\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 0s 535us/step - loss: 3.0606\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 0s 572us/step - loss: 3.2782\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 0s 545us/step - loss: 2.9525\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 0s 543us/step - loss: 3.7391\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 0s 575us/step - loss: 3.1395\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 0s 519us/step - loss: 2.9833\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 0s 524us/step - loss: 3.2004\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 0s 502us/step - loss: 2.9959\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 0s 526us/step - loss: 3.0281\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 0s 519us/step - loss: 3.1900\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 0s 509us/step - loss: 3.1354\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 0s 520us/step - loss: 2.9326\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 0s 473us/step - loss: 2.7754\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 0s 468us/step - loss: 3.4874\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 0s 499us/step - loss: 3.1137\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 0s 514us/step - loss: 2.8040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d93cd2fee0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[74.17014 ],\n",
       "       [65.7188  ],\n",
       "       [71.074265],\n",
       "       [71.84966 ],\n",
       "       [70.39557 ],\n",
       "       [64.64641 ],\n",
       "       [68.014465],\n",
       "       [66.31993 ],\n",
       "       [67.16507 ]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    73.847017\n",
       "1    68.781904\n",
       "2    74.110105\n",
       "3    71.730978\n",
       "4    69.881796\n",
       "5    67.253016\n",
       "6    68.785081\n",
       "7    68.348516\n",
       "8    67.018950\n",
       "Name: Height, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "A,B=model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[0,0]=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "B[0]=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights((A,B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.]], dtype=float32), array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-2.0]",
   "language": "python",
   "name": "conda-env-tf-2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
